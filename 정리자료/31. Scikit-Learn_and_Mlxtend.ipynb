{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn and Mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlxtend + scikit-learn 이라면 python으로 데이터 분석할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요즘 resemble 방식 중에 stacking이 가장 성능이 뛰어나다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분석하는 사람들은 통계적으로 하고 싶을 때는 stats model 쓰면 되고,\n",
    "기계학습 쓸 때는 mlxtend + scikit-learn으로 하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature selection에 관련해서는 scikit-feature라는 library를 통해서 여러가지 feature selection 방법을 적용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/f9/798cb32550dcbc9e0e3c143dc7144d2631df171423ed143cdb8b38ee2e5e/mlxtend-0.13.0-py2.py3-none-any.whl (1.3MB)\n",
      "Requirement already satisfied: scipy>=0.17 in d:\\anaconda3\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=1.5.1 in d:\\anaconda3\\lib\\site-packages (from mlxtend) (2.1.0)\n",
      "Requirement already satisfied: pandas>=0.17.1 in d:\\anaconda3\\lib\\site-packages (from mlxtend) (0.23.3)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from mlxtend) (36.7.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in d:\\anaconda3\\lib\\site-packages (from mlxtend) (1.13.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in d:\\anaconda3\\lib\\site-packages (from mlxtend) (0.19.1)\n",
      "Requirement already satisfied: six>=1.10 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=1.5.1->mlxtend) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=1.5.1->mlxtend) (2.6.1)\n",
      "Requirement already satisfied: pytz in d:\\anaconda3\\lib\\site-packages (from matplotlib>=1.5.1->mlxtend) (2017.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=1.5.1->mlxtend) (2.2.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mlxtend\n",
    ": Mlxtend(machine learning extensions)는 Data Science 업무에서 유용한 툴을 제공해주는 라이브러리이다.  \n",
    "[Link to Mlxtend UserGuide](https://rasbt.github.io/mlxtend/USER_GUIDE_INDEX/)  \n",
    "  \n",
    "### association rule : 보통 rule이 붙으면 data mining  \n",
    "association rule learning은 어떠한 2개의 아이템 집합이 빈번히 발생하는가를 알려주는 일련의 규칙을 생성하는 방법이다. \n",
    "대표적인 예로 마켓에서의 구매에 대한 연관 규칙을 생성하는 것이다.\n",
    "마켓에는 많은 종류의 상품을 파는데 소비자들이 상품을 구매하는 이력을 이용하여 상품간의 연관관계를 만들고, 관계 있는 상품, 관계 없는 상품 등을 구할 수 있도록 하는데 쓰인다.  \n",
    "\n",
    "[association rule에 대한 포스트 링크1](http://hackability.kr/entry/Data-Mining-11-%EC%97%B0%EA%B4%80-%EB%B2%95%EC%B9%99-Association-Rule-%EC%86%8C%EA%B0%9C)  \n",
    "[association rule에 대한 포스트 링크2](https://ratsgo.github.io/machine%20learning/2017/04/08/apriori/)  \n",
    "  \n",
    "두 가지 링크 모두 참고하면 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(Eggs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Milk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Onion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Yogurt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Eggs, Onion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Milk, Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Kidney Beans, Yogurt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Eggs, Kidney Beans, Onion)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support                     itemsets\n",
       "0       0.8                       (Eggs)\n",
       "1       1.0               (Kidney Beans)\n",
       "2       0.6                       (Milk)\n",
       "3       0.6                      (Onion)\n",
       "4       0.6                     (Yogurt)\n",
       "5       0.8         (Eggs, Kidney Beans)\n",
       "6       0.6                (Eggs, Onion)\n",
       "7       0.6         (Milk, Kidney Beans)\n",
       "8       0.6        (Kidney Beans, Onion)\n",
       "9       0.6       (Kidney Beans, Yogurt)\n",
       "10      0.6  (Eggs, Kidney Beans, Onion)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "# TransactionEncoder : 파이썬 리스트에서 transaction 데이터를 위한 인코더 클래스이다.\n",
    "#                      리스트의 리스트 형식의 데이터를 Numpy array로 인코딩해줌.\n",
    "# apriori : One-hot Dataframe에서 빈번한 itemset을 찾아준다.\n",
    "#           연관 룰 학습(association rule learning)에서 빈번한 itemset들을 추출해주는 알고리즘.\n",
    "\n",
    "dataset = [['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
    "           ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n",
    "           ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']]\n",
    "# 이중 리스트 형식.\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "# fit -> dataset내의 unique한 column들을 알아낸다. \n",
    "# transform -> dataset을 one-hot 인코딩된 Numpy boolean array로 반환해준다.\n",
    "# numpy의 ndarray형식으로 인코딩해준다.\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "# dataFrame객체로 반환해준다.\n",
    "frequent_itemsets = apriori(df, min_support=0.6, use_colnames=True)\n",
    "# 최소 support가 0.6이상인 item들에 대해서 item들의 열 인덱스들을 리턴해준다.\n",
    "# 즉 모든 itemset에서 60% 이상 등장하는 단어 셋을 골라주는 것이다.\n",
    "# use_colnames = True를 통해서 integer 값들을 대표하는 item이름으로 변환해준다.\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Milk)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Yogurt)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Eggs, Onion)</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              antecedents            consequents  antecedent support  \\\n",
       "0                  (Eggs)         (Kidney Beans)                 0.8   \n",
       "1          (Kidney Beans)                 (Eggs)                 1.0   \n",
       "2                  (Eggs)                (Onion)                 0.8   \n",
       "3                 (Onion)                 (Eggs)                 0.6   \n",
       "4                  (Milk)         (Kidney Beans)                 0.6   \n",
       "5                 (Onion)         (Kidney Beans)                 0.6   \n",
       "6                (Yogurt)         (Kidney Beans)                 0.6   \n",
       "7    (Eggs, Kidney Beans)                (Onion)                 0.8   \n",
       "8           (Eggs, Onion)         (Kidney Beans)                 0.6   \n",
       "9   (Kidney Beans, Onion)                 (Eggs)                 0.6   \n",
       "10                 (Eggs)  (Kidney Beans, Onion)                 0.8   \n",
       "11                (Onion)   (Eggs, Kidney Beans)                 0.6   \n",
       "\n",
       "    consequent support  support  confidence  lift  leverage  conviction  \n",
       "0                  1.0      0.8        1.00  1.00      0.00         inf  \n",
       "1                  0.8      0.8        0.80  1.00      0.00    1.000000  \n",
       "2                  0.6      0.6        0.75  1.25      0.12    1.600000  \n",
       "3                  0.8      0.6        1.00  1.25      0.12         inf  \n",
       "4                  1.0      0.6        1.00  1.00      0.00         inf  \n",
       "5                  1.0      0.6        1.00  1.00      0.00         inf  \n",
       "6                  1.0      0.6        1.00  1.00      0.00         inf  \n",
       "7                  0.6      0.6        0.75  1.25      0.12    1.600000  \n",
       "8                  1.0      0.6        1.00  1.00      0.00         inf  \n",
       "9                  0.8      0.6        1.00  1.25      0.12         inf  \n",
       "10                 0.6      0.6        0.75  1.25      0.12    1.600000  \n",
       "11                 0.8      0.6        1.00  1.25      0.12         inf  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "# 빈번한 itemset에서 association rules(연관 룰)을 만드는 함수이다.\n",
    "\n",
    "association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
    "# 이전에 만든 60%이상의 support를 지니는 itemset들에서\n",
    "# confidence에 있어서 최소 0.7 이상인 연관룰을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             antecedents            consequents  antecedent support  \\\n",
       "0                 (Eggs)                (Onion)                 0.8   \n",
       "1                (Onion)                 (Eggs)                 0.6   \n",
       "2   (Eggs, Kidney Beans)                (Onion)                 0.8   \n",
       "3  (Kidney Beans, Onion)                 (Eggs)                 0.6   \n",
       "4                 (Eggs)  (Kidney Beans, Onion)                 0.8   \n",
       "5                (Onion)   (Eggs, Kidney Beans)                 0.6   \n",
       "\n",
       "   consequent support  support  confidence  lift  leverage  conviction  \n",
       "0                 0.6      0.6        0.75  1.25      0.12    1.600000  \n",
       "1                 0.8      0.6        1.00  1.25      0.12         inf  \n",
       "2                 0.6      0.6        0.75  1.25      0.12    1.600000  \n",
       "3                 0.8      0.6        1.00  1.25      0.12         inf  \n",
       "4                 0.6      0.6        0.75  1.25      0.12    1.600000  \n",
       "5                 0.8      0.6        1.00  1.25      0.12         inf  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n",
    "rules\n",
    "# lift(향상도)가 최소 1.2가 넘는 연관 룰 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - support(A->C) = support(A+C) [aka 'support'], range: [0, 1]  \n",
    "  \n",
    " - confidence(A->C) = support(A+C) / support(A), range: [0, 1]  \n",
    "  \n",
    " - lift(A->C) = confidence(A->C) / support(C), range: [0, inf]  \n",
    "  \n",
    " - leverage(A->C) = support(A->C) - support(A)*support(C),\n",
    "    range: [-1, 1]  \n",
    "  \n",
    " - conviction = [1 - support(C)] / [1 - confidence(A->C)],\n",
    "    range: [0, inf]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>antecedant_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Onion)</td>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             antecedents            consequents  antecedent support  \\\n",
       "0                 (Eggs)                (Onion)                 0.8   \n",
       "1                (Onion)                 (Eggs)                 0.6   \n",
       "2   (Eggs, Kidney Beans)                (Onion)                 0.8   \n",
       "3  (Kidney Beans, Onion)                 (Eggs)                 0.6   \n",
       "4                 (Eggs)  (Kidney Beans, Onion)                 0.8   \n",
       "5                (Onion)   (Eggs, Kidney Beans)                 0.6   \n",
       "\n",
       "   consequent support  support  confidence  lift  leverage  conviction  \\\n",
       "0                 0.6      0.6        0.75  1.25      0.12    1.600000   \n",
       "1                 0.8      0.6        1.00  1.25      0.12         inf   \n",
       "2                 0.6      0.6        0.75  1.25      0.12    1.600000   \n",
       "3                 0.8      0.6        1.00  1.25      0.12         inf   \n",
       "4                 0.6      0.6        0.75  1.25      0.12    1.600000   \n",
       "5                 0.8      0.6        1.00  1.25      0.12         inf   \n",
       "\n",
       "   antecedant_len  \n",
       "0               1  \n",
       "1               1  \n",
       "2               2  \n",
       "3               2  \n",
       "4               1  \n",
       "5               1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[\"antecedant_len\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "rules\n",
    "# antecedents 항목 숫자 만큼 새로이 column을 만들어 추가."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>antecedant_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Kidney Beans, Onion)</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             antecedents consequents  antecedent support  consequent support  \\\n",
       "3  (Kidney Beans, Onion)      (Eggs)                 0.6                 0.8   \n",
       "\n",
       "   support  confidence  lift  leverage  conviction  antecedant_len  \n",
       "3      0.6         1.0  1.25      0.12         inf               2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[ (rules['antecedant_len'] >= 2) &\n",
    "       (rules['confidence'] > 0.75) &\n",
    "       (rules['lift'] > 1.2) ]\n",
    "# 이렇게 여러 조건에 맞는 연관룰을 찾아 낼 수 있다.(=필터링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>antecedant_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            antecedents consequents  antecedent support  consequent support  \\\n",
       "2  (Eggs, Kidney Beans)     (Onion)                 0.8                 0.6   \n",
       "\n",
       "   support  confidence  lift  leverage  conviction  antecedant_len  \n",
       "2      0.6        0.75  1.25      0.12         1.6               2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[rules['antecedents'] == {'Eggs', 'Kidney Beans'}]\n",
    "# 이것또한 원하는 조건에 맞는 연관룰 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemsets</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[177, 176]</td>\n",
       "      <td>0.253623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[177, 179]</td>\n",
       "      <td>0.253623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[176, 178]</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[176, 179]</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[93, 100]</td>\n",
       "      <td>0.181159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[177, 178]</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[177, 176, 178]</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          itemsets   support\n",
       "0       [177, 176]  0.253623\n",
       "1       [177, 179]  0.253623\n",
       "2       [176, 178]  0.217391\n",
       "3       [176, 179]  0.217391\n",
       "4        [93, 100]  0.181159\n",
       "5       [177, 178]  0.108696\n",
       "6  [177, 176, 178]  0.108696"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dict = {'itemsets': [['177', '176'], ['177', '179'],\n",
    "                     ['176', '178'], ['176', '179'],\n",
    "                     ['93', '100'], ['177', '178'],\n",
    "                     ['177', '176', '178']],\n",
    "        'support':[0.253623, 0.253623, 0.217391,\n",
    "                   0.217391, 0.181159, 0.108696, 0.108696]}\n",
    "\n",
    "freq_itemsets = pd.DataFrame(dict)\n",
    "freq_itemsets # itemset과 해당 지지도를 지니는 DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(177)</td>\n",
       "      <td>(176)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(176)</td>\n",
       "      <td>(177)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(177)</td>\n",
       "      <td>(179)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(179)</td>\n",
       "      <td>(177)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(178)</td>\n",
       "      <td>(176)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(176)</td>\n",
       "      <td>(178)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(179)</td>\n",
       "      <td>(176)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(176)</td>\n",
       "      <td>(179)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(100)</td>\n",
       "      <td>(93)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(93)</td>\n",
       "      <td>(100)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(178)</td>\n",
       "      <td>(177)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(177)</td>\n",
       "      <td>(178)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(178, 177)</td>\n",
       "      <td>(176)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(178, 176)</td>\n",
       "      <td>(177)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(177, 176)</td>\n",
       "      <td>(178)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(178)</td>\n",
       "      <td>(177, 176)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(177)</td>\n",
       "      <td>(178, 176)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(176)</td>\n",
       "      <td>(178, 177)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support   support  \\\n",
       "0        (177)       (176)                 NaN                 NaN  0.253623   \n",
       "1        (176)       (177)                 NaN                 NaN  0.253623   \n",
       "2        (177)       (179)                 NaN                 NaN  0.253623   \n",
       "3        (179)       (177)                 NaN                 NaN  0.253623   \n",
       "4        (178)       (176)                 NaN                 NaN  0.217391   \n",
       "5        (176)       (178)                 NaN                 NaN  0.217391   \n",
       "6        (179)       (176)                 NaN                 NaN  0.217391   \n",
       "7        (176)       (179)                 NaN                 NaN  0.217391   \n",
       "8        (100)        (93)                 NaN                 NaN  0.181159   \n",
       "9         (93)       (100)                 NaN                 NaN  0.181159   \n",
       "10       (178)       (177)                 NaN                 NaN  0.108696   \n",
       "11       (177)       (178)                 NaN                 NaN  0.108696   \n",
       "12  (178, 177)       (176)                 NaN                 NaN  0.108696   \n",
       "13  (178, 176)       (177)                 NaN                 NaN  0.108696   \n",
       "14  (177, 176)       (178)                 NaN                 NaN  0.108696   \n",
       "15       (178)  (177, 176)                 NaN                 NaN  0.108696   \n",
       "16       (177)  (178, 176)                 NaN                 NaN  0.108696   \n",
       "17       (176)  (178, 177)                 NaN                 NaN  0.108696   \n",
       "\n",
       "    confidence  lift  leverage  conviction  \n",
       "0          NaN   NaN       NaN         NaN  \n",
       "1          NaN   NaN       NaN         NaN  \n",
       "2          NaN   NaN       NaN         NaN  \n",
       "3          NaN   NaN       NaN         NaN  \n",
       "4          NaN   NaN       NaN         NaN  \n",
       "5          NaN   NaN       NaN         NaN  \n",
       "6          NaN   NaN       NaN         NaN  \n",
       "7          NaN   NaN       NaN         NaN  \n",
       "8          NaN   NaN       NaN         NaN  \n",
       "9          NaN   NaN       NaN         NaN  \n",
       "10         NaN   NaN       NaN         NaN  \n",
       "11         NaN   NaN       NaN         NaN  \n",
       "12         NaN   NaN       NaN         NaN  \n",
       "13         NaN   NaN       NaN         NaN  \n",
       "14         NaN   NaN       NaN         NaN  \n",
       "15         NaN   NaN       NaN         NaN  \n",
       "16         NaN   NaN       NaN         NaN  \n",
       "17         NaN   NaN       NaN         NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "res = association_rules(freq_itemsets, support_only=True, min_threshold=0.1)\n",
    "res # support_only는 support이외 다른 것들은 계산하지 않도록 해준다.\n",
    "# 이것은 \"cropped(잘린)\" DataFrame으로 item의 subset에 대하여 support값을 지니지 않기 때문에\n",
    "# 이것은 연관 룰을 계산할 때 문제를 야기 할 수 있다.\n",
    "# 그래서 support_only 플래그는 주어진 rule의 support에 대해서만 계산 하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(177)</td>\n",
       "      <td>(176)</td>\n",
       "      <td>0.253623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(176)</td>\n",
       "      <td>(177)</td>\n",
       "      <td>0.253623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(177)</td>\n",
       "      <td>(179)</td>\n",
       "      <td>0.253623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(179)</td>\n",
       "      <td>(177)</td>\n",
       "      <td>0.253623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(178)</td>\n",
       "      <td>(176)</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(176)</td>\n",
       "      <td>(178)</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(179)</td>\n",
       "      <td>(176)</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(176)</td>\n",
       "      <td>(179)</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(100)</td>\n",
       "      <td>(93)</td>\n",
       "      <td>0.181159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(93)</td>\n",
       "      <td>(100)</td>\n",
       "      <td>0.181159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(178)</td>\n",
       "      <td>(177)</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(177)</td>\n",
       "      <td>(178)</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(178, 177)</td>\n",
       "      <td>(176)</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(178, 176)</td>\n",
       "      <td>(177)</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(177, 176)</td>\n",
       "      <td>(178)</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(178)</td>\n",
       "      <td>(177, 176)</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(177)</td>\n",
       "      <td>(178, 176)</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(176)</td>\n",
       "      <td>(178, 177)</td>\n",
       "      <td>0.108696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents   support\n",
       "0        (177)       (176)  0.253623\n",
       "1        (176)       (177)  0.253623\n",
       "2        (177)       (179)  0.253623\n",
       "3        (179)       (177)  0.253623\n",
       "4        (178)       (176)  0.217391\n",
       "5        (176)       (178)  0.217391\n",
       "6        (179)       (176)  0.217391\n",
       "7        (176)       (179)  0.217391\n",
       "8        (100)        (93)  0.181159\n",
       "9         (93)       (100)  0.181159\n",
       "10       (178)       (177)  0.108696\n",
       "11       (177)       (178)  0.108696\n",
       "12  (178, 177)       (176)  0.108696\n",
       "13  (178, 176)       (177)  0.108696\n",
       "14  (177, 176)       (178)  0.108696\n",
       "15       (178)  (177, 176)  0.108696\n",
       "16       (177)  (178, 176)  0.108696\n",
       "17       (176)  (178, 177)  0.108696"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = res[['antecedents', 'consequents', 'support']]\n",
    "res # 원하는 데이터만 필터링해서 갖고 온다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris() # iris 데이터를 갖고 온다.\n",
    "X, y = iris.data[:, 1:3], iris.target # input값과 target값을 할당."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation:\n",
      "\n",
      "Accuracy: 0.91 (+/- 0.01) [KNN]\n",
      "Accuracy: 0.91 (+/- 0.06) [Random Forest]\n",
      "Accuracy: 0.92 (+/- 0.03) [Naive Bayes]\n",
      "Accuracy: 0.95 (+/- 0.03) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# 갈래상 맨 끝에서 binary classfication을 해줌\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN 분류기\n",
    "from sklearn.naive_bayes import GaussianNB  #나이브 베이즈\n",
    "from sklearn.ensemble import RandomForestClassifier # resemble로 만든 classifier\n",
    "# Random Forest : 여러 가지의 decision tree들을 임의적(randomly)으로 학습하는 방식의 resemble방식이다.\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "# stacking은 다수의 분류 모델들을 결합한 resemble 학습 방식이다.\n",
    "import numpy as np\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1) # KNN 분류기\n",
    "clf2 = RandomForestClassifier(random_state=1) # Random Forest 분류기\n",
    "clf3 = GaussianNB() # 나이브 베이즈\n",
    "lr = LogisticRegression() # 로지스틱회귀\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                          meta_classifier=lr) # fitting\n",
    "# KNN, 나이브베이즈, Random Forest 방식으로 분류된 Prediction들을 meta-classifier인\n",
    "# 로지스틱 회귀에 넣어서 최종 결과값을 내준다.\n",
    "\n",
    "print('3-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, sclf], \n",
    "                      ['KNN', \n",
    "                       'Random Forest', \n",
    "                       'Naive Bayes',\n",
    "                       'StackingClassifier']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X, y, \n",
    "                                              cv=3, scoring='accuracy')\n",
    "    # 3등분한 cross-validation방식으로 각 모델에 넣어서 accuracy(정확도)를 구해준다.\n",
    "    \n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHiCAYAAAD1WPj+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyIE/AdV5UgOs/UDEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2af9d3ba978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "# 1차원이나 2차원으로 분류기의 decision region들을 plotting해주는 함수\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "gs = gridspec.GridSpec(2, 2) # 2,2 크기로 Grid 생성\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "for clf, lab, grd in zip([clf1, clf2, clf3, sclf], \n",
    "                         ['KNN', \n",
    "                          'Random Forest', \n",
    "                          'Naive Bayes',\n",
    "                          'StackingClassifier'],\n",
    "                          itertools.product([0, 1], repeat=2)):\n",
    "\n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf)\n",
    "    plt.title(lab)\n",
    "# 그래프 시각화 해서 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle에서 No Free Hunch를 보면 어떤 새로운 기법이나 1등한 사람들의 기법을 공부할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "estimator에 최적의 parameter값을 찾을 수 있도록 도와주는 기능이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': 1,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# estimator에 parameter값들을 수정해서 검사할 수 있도록 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors': [3,4,5,6,7,8,9,10,11,12,13,14]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(knn, param_grid= param_grid, cv=10) # 10-fold cross-validation\n",
    "# knn 모델을 cross-validation을 3~14까지 해준다.\n",
    "# 그래서 가장 성능이 좋은 parameter를 찾기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(data.data, data.target) # fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 13}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_ # 가장 성능이 좋았던 parameter\n",
    "# n이 13일 때 가장 성능이 좋다. KNeighbor에서 k=13일 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97999999999999998"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_ # 가장 높은 스코어\n",
    "# k=13일 때의 스코어 := 가장 높은 스코어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_estimator_': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
       "            weights='uniform'),\n",
       " 'best_index_': 10,\n",
       " 'best_params_': {'n_neighbors': 13},\n",
       " 'best_score_': 0.97999999999999998,\n",
       " 'cv': 10,\n",
       " 'cv_results_': {'mean_fit_time': array([  1.59864426e-03,   9.97638702e-04,   8.97288322e-04,\n",
       "           7.97605515e-04,   3.98993492e-04,   2.99191475e-04,\n",
       "           9.97304916e-05,   9.97304916e-05,   3.98993492e-04,\n",
       "           3.99112701e-04,   3.98826599e-04,   1.99532509e-04]),\n",
       "  'mean_score_time': array([ 0.00219533,  0.00109663,  0.00847728,  0.00109677,  0.00049884,\n",
       "          0.00059843,  0.00069804,  0.00069799,  0.00039897,  0.00049815,\n",
       "          0.00049891,  0.0007021 ]),\n",
       "  'mean_test_score': array([ 0.96666667,  0.96666667,  0.96666667,  0.96666667,  0.96666667,\n",
       "          0.96666667,  0.97333333,  0.96666667,  0.96666667,  0.97333333,\n",
       "          0.98      ,  0.97333333]),\n",
       "  'mean_train_score': array([ 0.96074074,  0.9637037 ,  0.96888889,  0.97259259,  0.97333333,\n",
       "          0.97925926,  0.97925926,  0.9762963 ,  0.98      ,  0.97851852,\n",
       "          0.98      ,  0.97925926]),\n",
       "  'param_n_neighbors': masked_array(data = [3 4 5 6 7 8 9 10 11 12 13 14],\n",
       "               mask = [False False False False False False False False False False False False],\n",
       "         fill_value = ?),\n",
       "  'params': [{'n_neighbors': 3},\n",
       "   {'n_neighbors': 4},\n",
       "   {'n_neighbors': 5},\n",
       "   {'n_neighbors': 6},\n",
       "   {'n_neighbors': 7},\n",
       "   {'n_neighbors': 8},\n",
       "   {'n_neighbors': 9},\n",
       "   {'n_neighbors': 10},\n",
       "   {'n_neighbors': 11},\n",
       "   {'n_neighbors': 12},\n",
       "   {'n_neighbors': 13},\n",
       "   {'n_neighbors': 14}],\n",
       "  'rank_test_score': array([5, 5, 5, 5, 5, 5, 2, 5, 5, 2, 1, 2]),\n",
       "  'split0_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       "  'split0_train_score': array([ 0.95555556,  0.95555556,  0.96296296,  0.97037037,  0.96296296,\n",
       "          0.97037037,  0.97037037,  0.97037037,  0.97037037,  0.97037037,\n",
       "          0.97777778,  0.97037037]),\n",
       "  'split1_test_score': array([ 0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "          0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "          0.93333333,  0.93333333]),\n",
       "  'split1_train_score': array([ 0.96296296,  0.96296296,  0.97037037,  0.97037037,  0.97777778,\n",
       "          0.98518519,  0.98518519,  0.98518519,  0.98518519,  0.99259259,\n",
       "          0.97777778,  0.97777778]),\n",
       "  'split2_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       "  'split2_train_score': array([ 0.95555556,  0.95555556,  0.96296296,  0.97037037,  0.97037037,\n",
       "          0.97777778,  0.97777778,  0.97777778,  0.98518519,  0.98518519,\n",
       "          0.97777778,  0.98518519]),\n",
       "  'split3_test_score': array([ 0.93333333,  0.93333333,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  1.        ]),\n",
       "  'split3_train_score': array([ 0.96296296,  0.96296296,  0.97037037,  0.97777778,  0.97037037,\n",
       "          0.98518519,  0.98518519,  0.97777778,  0.97777778,  0.97777778,\n",
       "          0.97777778,  0.97777778]),\n",
       "  'split4_test_score': array([ 0.86666667,  0.86666667,  0.86666667,  0.86666667,  0.86666667,\n",
       "          1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "          1.        ,  1.        ]),\n",
       "  'split4_train_score': array([ 0.97777778,  0.97777778,  0.98518519,  0.98518519,  0.98518519,\n",
       "          0.97777778,  0.97777778,  0.97777778,  0.98518519,  0.97777778,\n",
       "          0.98518519,  0.97777778]),\n",
       "  'split5_test_score': array([ 1.        ,  1.        ,  0.93333333,  0.93333333,  0.93333333,\n",
       "          0.86666667,  0.93333333,  0.86666667,  0.86666667,  0.93333333,\n",
       "          0.93333333,  0.86666667]),\n",
       "  'split5_train_score': array([ 0.95555556,  0.96296296,  0.96296296,  0.95555556,  0.97037037,\n",
       "          0.97037037,  0.97777778,  0.97037037,  0.98518519,  0.97777778,\n",
       "          0.98518519,  0.97777778]),\n",
       "  'split6_test_score': array([ 0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "          0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "          0.93333333,  0.93333333]),\n",
       "  'split6_train_score': array([ 0.97037037,  0.97037037,  0.97777778,  0.98518519,  0.97777778,\n",
       "          0.99259259,  0.99259259,  0.98518519,  0.99259259,  0.98518519,\n",
       "          0.99259259,  0.99259259]),\n",
       "  'split7_test_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "          0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "          1.        ,  1.        ]),\n",
       "  'split7_train_score': array([ 0.95555556,  0.96296296,  0.96296296,  0.97037037,  0.97037037,\n",
       "          0.97777778,  0.97037037,  0.97777778,  0.97777778,  0.97037037,\n",
       "          0.97037037,  0.97777778]),\n",
       "  'split8_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       "  'split8_train_score': array([ 0.95555556,  0.95555556,  0.96296296,  0.97037037,  0.97037037,\n",
       "          0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.98518519,\n",
       "          0.97777778,  0.98518519]),\n",
       "  'split9_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       "  'split9_train_score': array([ 0.95555556,  0.97037037,  0.97037037,  0.97037037,  0.97777778,\n",
       "          0.97777778,  0.97777778,  0.96296296,  0.96296296,  0.96296296,\n",
       "          0.97777778,  0.97037037]),\n",
       "  'std_fit_time': array([ 0.00048408,  0.00077282,  0.0002991 ,  0.0003988 ,  0.00048867,\n",
       "          0.00045702,  0.00029919,  0.00029919,  0.00048867,  0.00048881,\n",
       "          0.00048846,  0.00039907]),\n",
       "  'std_score_time': array([ 0.00107351,  0.00029941,  0.02310791,  0.00029904,  0.00049884,\n",
       "          0.00048862,  0.00045698,  0.00045694,  0.00048864,  0.00049816,\n",
       "          0.00049892,  0.0004598 ]),\n",
       "  'std_test_score': array([ 0.04472136,  0.04472136,  0.04472136,  0.04472136,  0.04472136,\n",
       "          0.04472136,  0.03265986,  0.04472136,  0.04472136,  0.03265986,\n",
       "          0.0305505 ,  0.04422166]),\n",
       "  'std_train_score': array([ 0.00744435,  0.00698813,  0.00725775,  0.00814815,  0.00592593,\n",
       "          0.00645763,  0.00645763,  0.00645763,  0.00814815,  0.0084132 ,\n",
       "          0.00578537,  0.00645763])},\n",
       " 'error_score': 'raise',\n",
       " 'estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       " 'fit_params': None,\n",
       " 'iid': True,\n",
       " 'multimetric_': False,\n",
       " 'n_jobs': 1,\n",
       " 'n_splits_': 10,\n",
       " 'param_grid': {'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': 'warn',\n",
       " 'scorer_': <function sklearn.metrics.scorer._passthrough_scorer>,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.__dict__\n",
    "# grid를 dict형식으로 출력해줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " '_abc_registry',\n",
       " '_check_is_fitted',\n",
       " '_estimator_type',\n",
       " '_get_param_iterator',\n",
       " '_get_param_names',\n",
       " 'best_estimator_',\n",
       " 'best_index_',\n",
       " 'best_params_',\n",
       " 'best_score_',\n",
       " 'classes_',\n",
       " 'cv',\n",
       " 'cv_results_',\n",
       " 'decision_function',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'fit',\n",
       " 'fit_params',\n",
       " 'get_params',\n",
       " 'grid_scores_',\n",
       " 'iid',\n",
       " 'inverse_transform',\n",
       " 'multimetric_',\n",
       " 'n_jobs',\n",
       " 'n_splits_',\n",
       " 'param_grid',\n",
       " 'pre_dispatch',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'refit',\n",
       " 'return_train_score',\n",
       " 'score',\n",
       " 'scorer_',\n",
       " 'scoring',\n",
       " 'set_params',\n",
       " 'transform',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(grid)\n",
    "\n",
    "#  'best_estimator_',\n",
    "#  'best_index_',\n",
    "#  'best_params_',\n",
    "#  'best_score_',\n",
    "#  'cv_results_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  1.59864426e-03,   9.97638702e-04,   8.97288322e-04,\n",
       "          7.97605515e-04,   3.98993492e-04,   2.99191475e-04,\n",
       "          9.97304916e-05,   9.97304916e-05,   3.98993492e-04,\n",
       "          3.99112701e-04,   3.98826599e-04,   1.99532509e-04]),\n",
       " 'mean_score_time': array([ 0.00219533,  0.00109663,  0.00847728,  0.00109677,  0.00049884,\n",
       "         0.00059843,  0.00069804,  0.00069799,  0.00039897,  0.00049815,\n",
       "         0.00049891,  0.0007021 ]),\n",
       " 'mean_test_score': array([ 0.96666667,  0.96666667,  0.96666667,  0.96666667,  0.96666667,\n",
       "         0.96666667,  0.97333333,  0.96666667,  0.96666667,  0.97333333,\n",
       "         0.98      ,  0.97333333]),\n",
       " 'mean_train_score': array([ 0.96074074,  0.9637037 ,  0.96888889,  0.97259259,  0.97333333,\n",
       "         0.97925926,  0.97925926,  0.9762963 ,  0.98      ,  0.97851852,\n",
       "         0.98      ,  0.97925926]),\n",
       " 'param_n_neighbors': masked_array(data = [3 4 5 6 7 8 9 10 11 12 13 14],\n",
       "              mask = [False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'n_neighbors': 3},\n",
       "  {'n_neighbors': 4},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 6},\n",
       "  {'n_neighbors': 7},\n",
       "  {'n_neighbors': 8},\n",
       "  {'n_neighbors': 9},\n",
       "  {'n_neighbors': 10},\n",
       "  {'n_neighbors': 11},\n",
       "  {'n_neighbors': 12},\n",
       "  {'n_neighbors': 13},\n",
       "  {'n_neighbors': 14}],\n",
       " 'rank_test_score': array([5, 5, 5, 5, 5, 5, 2, 5, 5, 2, 1, 2]),\n",
       " 'split0_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split0_train_score': array([ 0.95555556,  0.95555556,  0.96296296,  0.97037037,  0.96296296,\n",
       "         0.97037037,  0.97037037,  0.97037037,  0.97037037,  0.97037037,\n",
       "         0.97777778,  0.97037037]),\n",
       " 'split1_test_score': array([ 0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333]),\n",
       " 'split1_train_score': array([ 0.96296296,  0.96296296,  0.97037037,  0.97037037,  0.97777778,\n",
       "         0.98518519,  0.98518519,  0.98518519,  0.98518519,  0.99259259,\n",
       "         0.97777778,  0.97777778]),\n",
       " 'split2_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split2_train_score': array([ 0.95555556,  0.95555556,  0.96296296,  0.97037037,  0.97037037,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.98518519,  0.98518519,\n",
       "         0.97777778,  0.98518519]),\n",
       " 'split3_test_score': array([ 0.93333333,  0.93333333,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ]),\n",
       " 'split3_train_score': array([ 0.96296296,  0.96296296,  0.97037037,  0.97777778,  0.97037037,\n",
       "         0.98518519,  0.98518519,  0.97777778,  0.97777778,  0.97777778,\n",
       "         0.97777778,  0.97777778]),\n",
       " 'split4_test_score': array([ 0.86666667,  0.86666667,  0.86666667,  0.86666667,  0.86666667,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ]),\n",
       " 'split4_train_score': array([ 0.97777778,  0.97777778,  0.98518519,  0.98518519,  0.98518519,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.98518519,  0.97777778,\n",
       "         0.98518519,  0.97777778]),\n",
       " 'split5_test_score': array([ 1.        ,  1.        ,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.86666667,  0.93333333,  0.86666667,  0.86666667,  0.93333333,\n",
       "         0.93333333,  0.86666667]),\n",
       " 'split5_train_score': array([ 0.95555556,  0.96296296,  0.96296296,  0.95555556,  0.97037037,\n",
       "         0.97037037,  0.97777778,  0.97037037,  0.98518519,  0.97777778,\n",
       "         0.98518519,  0.97777778]),\n",
       " 'split6_test_score': array([ 0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         0.93333333,  0.93333333]),\n",
       " 'split6_train_score': array([ 0.97037037,  0.97037037,  0.97777778,  0.98518519,  0.97777778,\n",
       "         0.99259259,  0.99259259,  0.98518519,  0.99259259,  0.98518519,\n",
       "         0.99259259,  0.99259259]),\n",
       " 'split7_test_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.93333333,  0.93333333,  0.93333333,  0.93333333,  0.93333333,\n",
       "         1.        ,  1.        ]),\n",
       " 'split7_train_score': array([ 0.95555556,  0.96296296,  0.96296296,  0.97037037,  0.97037037,\n",
       "         0.97777778,  0.97037037,  0.97777778,  0.97777778,  0.97037037,\n",
       "         0.97037037,  0.97777778]),\n",
       " 'split8_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split8_train_score': array([ 0.95555556,  0.95555556,  0.96296296,  0.97037037,  0.97037037,\n",
       "         0.97777778,  0.97777778,  0.97777778,  0.97777778,  0.98518519,\n",
       "         0.97777778,  0.98518519]),\n",
       " 'split9_test_score': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'split9_train_score': array([ 0.95555556,  0.97037037,  0.97037037,  0.97037037,  0.97777778,\n",
       "         0.97777778,  0.97777778,  0.96296296,  0.96296296,  0.96296296,\n",
       "         0.97777778,  0.97037037]),\n",
       " 'std_fit_time': array([ 0.00048408,  0.00077282,  0.0002991 ,  0.0003988 ,  0.00048867,\n",
       "         0.00045702,  0.00029919,  0.00029919,  0.00048867,  0.00048881,\n",
       "         0.00048846,  0.00039907]),\n",
       " 'std_score_time': array([ 0.00107351,  0.00029941,  0.02310791,  0.00029904,  0.00049884,\n",
       "         0.00048862,  0.00045698,  0.00045694,  0.00048864,  0.00049816,\n",
       "         0.00049892,  0.0004598 ]),\n",
       " 'std_test_score': array([ 0.04472136,  0.04472136,  0.04472136,  0.04472136,  0.04472136,\n",
       "         0.04472136,  0.03265986,  0.04472136,  0.04472136,  0.03265986,\n",
       "         0.0305505 ,  0.04422166]),\n",
       " 'std_train_score': array([ 0.00744435,  0.00698813,  0.00725775,  0.00814815,  0.00592593,\n",
       "         0.00645763,  0.00645763,  0.00645763,  0.00814815,  0.0084132 ,\n",
       "         0.00578537,  0.00645763])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stacking cv -> cross validation을 통해 gridsearchcv를 해서 최적의 parameter를 찾아낼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV는 꼭 알아야한다!!! 굉장히 중요!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseSearchCV.score of GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gridsearchCV안에 stacking, resemble 기법을 적용할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
