{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn and Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits # 숫자 데이터셋\n",
    "import numpy as np \n",
    "digits = load_digits() # 숫자 데이터 셋 로드해온다.\n",
    "digits.keys() # 해당 데이터셋의 Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
       "       ..., \n",
       "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
       "       [  0.,   0.,  10., ...,  12.,   1.,   0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data # 해당 데이터셋의 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target # 해당 데이터셋의 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optical Recognition of Handwritten Digits Data Set\n",
      "===================================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      "References\n",
      "----------\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR) # 손글씨 인식하는 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 ,음악, 영상같은 데이터의 경우 pandas로 바꿀 필요가 없다. -> 의미가 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape # 데이터의 shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape # target의 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.dtype # data type -> 숫자가 아닐 경우 숫자화 해주어야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178, 182, 177, 183, 181, 182, 181, 179, 174, 180], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(digits.target) \n",
    "# value_count()와 비슷한 기능을 함. 개수 정보 얻어옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fb840a73c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAECCAYAAADesWqHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAC/tJREFUeJzt3fGr1fUdx/HXa1dDLcvbdGFZ3QVD\niGApIhMhnFbYEgexHxSKzA33wxbJBlGDGP0D0X4YQVityIyyhBFbS8qI0OXUbFnaKLmhs/KKlaY0\nsd774XwdTtzu99r9fO659/18wMFz7z33vN7Xy+t8v+ec7/1+HBECkMu3RnoAAPVRfCAhig8kRPGB\nhCg+kBDFBxLqiuLbXmz7Pdvv276ncNajtg/a3lUy57S8y21vsr3b9ju27yqcN8H2VttvNXn3l8xr\nMntsv2n7hdJZTV6/7bdt77S9rXDWFNvrbe9pfofzCmbNbH6mU5cjtlcXCYuIEb1I6pH0gaSrJJ0n\n6S1JVxfMu07SbEm7Kv180yXNbq5PlvSPwj+fJV3QXB8v6Q1JPyj8M/5K0lOSXqj0f9ovaWqlrMcl\n/ay5fp6kKZVyeyR9LOnKEvffDVv8uZLej4i9EXFC0tOSflwqLCJek3S41P2fJe+jiNjRXD8qabek\nywrmRUR80Xw4vrkUO0rL9gxJN0taUypjpNi+UJ0NxSOSFBEnIuKzSvGLJH0QER+WuPNuKP5lkvad\n9vF+FSzGSLLdJ2mWOlvhkjk9tndKOihpY0SUzHtQ0t2Svi6YcaaQ9JLt7bZXFcy5StKApMeapzJr\nbJ9fMO90yyStK3Xn3VB8n+VzY+44YtsXSHpO0uqIOFIyKyK+iohrJc2QNNf2NSVybC+RdDAitpe4\n//9jfkTMlnSTpF/Yvq5Qzjh1nhY+FBGzJB2TVPQ1KEmyfZ6kpZKeLZXRDcXfL+ny0z6eIenACM1S\nhO3x6pR+bUQ8Xyu32S19VdLiQhHzJS213a/OU7SFtp8slPUfEXGg+fegpA3qPF0sYb+k/aftMa1X\n54GgtJsk7YiIT0oFdEPx/ybpe7a/2zzSLZP0xxGeadjYtjrPEXdHxAMV8qbZntJcnyjpekl7SmRF\nxL0RMSMi+tT5vb0SEbeWyDrF9vm2J5+6LulGSUXeoYmIjyXtsz2z+dQiSe+WyDrDchXczZc6uzIj\nKiJO2v6lpL+o80rmoxHxTqk82+skLZA01fZ+Sb+NiEdK5amzVbxN0tvN825J+k1E/KlQ3nRJj9vu\nUeeB/ZmIqPI2WyWXSNrQeTzVOElPRcSLBfPulLS22SjtlXRHwSzZniTpBkk/L5rTvHUAIJFu2NUH\nUBnFBxKi+EBCFB9IiOIDCXVV8QsffjliWeSR1215XVV8STX/c6v+Iskjr5vyuq34ACoocgDP1KlT\no6+vb8jfNzAwoGnTpg37PMOddezYsSF/z6effqre3t5zyuvv7x/y95w8eVLjxp3bgZlTpkwZ8vcc\nP35ckyZNOqe8Sy+9dMjf801+f81Rf9XyzsW55vX39+vQoUOD/oBFDtnt6+vTtm1FT4wyorZs2VI1\nb+XKlVXzbrnllqp59913X9W8CRMmVM2rac6cOa1ux64+kBDFBxKi+EBCFB9IiOIDCVF8ICGKDyRE\n8YGEWhW/5hJXAMobtPjNSRt/r84pf6+WtNz21aUHA1BOmy1+1SWuAJTXpvhplrgCsmhT/FZLXNle\nZXub7W0DAwPffDIAxbQpfqslriLi4YiYExFzav75IoCha1P8Mb3EFZDRoH+PX3uJKwDltToRR7PO\nW6m13gBUxpF7QEIUH0iI4gMJUXwgIYoPJETxgYQoPpAQxQcSKrKSzlhXe2WbPXv2VM07fPhw1byJ\nEydWzdu8eXPVvHnz5lXNa4MtPpAQxQcSovhAQhQfSIjiAwlRfCAhig8kRPGBhCg+kBDFBxJqs4TW\no7YP2t5VYyAA5bXZ4v9B0uLCcwCoaNDiR8Rrkur+1QaAoniODyQ0bMVn7Txg9Bi24rN2HjB6sKsP\nJNTm7bx1krZImml7v+2flh8LQEltFs1cXmMQAPWwqw8kRPGBhCg+kBDFBxKi+EBCFB9IiOIDCVF8\nIKExsXbevn37quaN9bXsent7q+bV/vlYO48tPpASxQcSovhAQhQfSIjiAwlRfCAhig8kRPGBhCg+\nkBDFBxJqc7LNy21vsr3b9ju276oxGIBy2hyrf1LSryNih+3Jkrbb3hgR7xaeDUAhbdbO+ygidjTX\nj0raLemy0oMBKGdIz/Ft90maJemNEsMAqKN18W1fIOk5Sasj4shZvs7aecAo0ar4tserU/q1EfH8\n2W7D2nnA6NHmVX1LekTS7oh4oPxIAEprs8WfL+k2SQtt72wuPyo8F4CC2qyd97okV5gFQCUcuQck\nRPGBhCg+kBDFBxKi+EBCFB9IiOIDCVF8IKExsXbe0aNHq+YtWLCgal7ttexqmzt37kiPkA5bfCAh\nig8kRPGBhCg+kBDFBxKi+EBCFB9IiOIDCVF8ICGKDyTU5iy7E2xvtf1Ws3be/TUGA1BOm2P1/yVp\nYUR80Zxf/3Xbf46IvxaeDUAhbc6yG5K+aD4c31yi5FAAymq7kk6P7Z2SDkraGBGsnQeMYq2KHxFf\nRcS1kmZImmv7mjNvw9p5wOgxpFf1I+IzSa9KWnyWr7F2HjBKtHlVf5rtKc31iZKul7Sn9GAAymnz\nqv50SY/b7lHngeKZiHih7FgASmrzqv7fJc2qMAuASjhyD0iI4gMJUXwgIYoPJETxgYQoPpAQxQcS\novhAQmNi7bzPP/+8at6SJUuq5o11hw8frpp38cUXV83rRmzxgYQoPpAQxQcSovhAQhQfSIjiAwlR\nfCAhig8kRPGBhCg+kFDr4jeLarxpmxNtAqPcULb4d0naXWoQAPW0XUJrhqSbJa0pOw6AGtpu8R+U\ndLekrwvOAqCSNivpLJF0MCK2D3I71s4DRok2W/z5kpba7pf0tKSFtp8880asnQeMHoMWPyLujYgZ\nEdEnaZmkVyLi1uKTASiG9/GBhIZ06q2IeFWdZbIBjGJs8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwg\nIYoPJDQm1s676KKLquZt3bq1al5tX375ZdW8zZs3V81bsWJF1bxuxBYfSIjiAwlRfCAhig8kRPGB\nhCg+kBDFBxKi+EBCFB9IiOIDCbU6ZLc5tfZRSV9JOhkRc0oOBaCsoRyr/8OIOFRsEgDVsKsPJNS2\n+CHpJdvbba8qORCA8tru6s+PiAO2vyNpo+09EfHa6TdoHhBWSdIVV1wxzGMCGE6ttvgRcaD596Ck\nDZLmnuU2rJ0HjBJtVss93/bkU9cl3ShpV+nBAJTTZlf/EkkbbJ+6/VMR8WLRqQAUNWjxI2KvpO9X\nmAVAJbydByRE8YGEKD6QEMUHEqL4QEIUH0iI4gMJUXwgoTGxdt706dOr5r388stV87Zs2VI174kn\nnqiaV9vtt98+0iOMOLb4QEIUH0iI4gMJUXwgIYoPJETxgYQoPpAQxQcSovhAQhQfSKhV8W1Psb3e\n9h7bu23PKz0YgHLaHqv/O0kvRsRPbJ8naVLBmQAUNmjxbV8o6TpJKyQpIk5IOlF2LAAltdnVv0rS\ngKTHbL9pe02zsMZ/sb3K9jbb2wYGBoZ9UADDp03xx0maLemhiJgl6Zike868EUtoAaNHm+Lvl7Q/\nIt5oPl6vzgMBgFFq0OJHxMeS9tme2XxqkaR3i04FoKi2r+rfKWlt84r+Xkl3lBsJQGmtih8ROyXN\nKTwLgEo4cg9IiOIDCVF8ICGKDyRE8YGEKD6QEMUHEqL4QEJjYu283t7eqnm115ZbuXJl1bwFCxZU\nzdu0aVPVPLDFB1Ki+EBCFB9IiOIDCVF8ICGKDyRE8YGEKD6QEMUHEhq0+LZn2t552uWI7dU1hgNQ\nxqCH7EbEe5KulSTbPZL+KWlD4bkAFDTUXf1Fkj6IiA9LDAOgjqEWf5mkdSUGAVBP6+I359RfKunZ\n//F11s4DRomhbPFvkrQjIj452xdZOw8YPYZS/OViNx8YE1oV3/YkSTdIer7sOABqaLuE1nFJ3y48\nC4BKOHIPSIjiAwlRfCAhig8kRPGBhCg+kBDFBxKi+EBCFB9IyBEx/HdqD0g6l7/Znyrp0DCP0w1Z\n5JFXK+/KiBj0r+SKFP9c2d4WEXPGWhZ55HVbHrv6QEIUH0io24r/8BjNIo+8rsrrquf4AOroti0+\ngAooPpAQxQcSovhAQhQfSOjfDivPcsTHuMIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fb82368a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# inline을 통해서 notebook상에서 plot을 볼 수 있게 해준다.\n",
    "x = digits.data[0].reshape(8,8) # 64차원의 벡터를 8 x 8의 matrix로 reshape해줌.\n",
    "plt.matshow(x, cmap=plt.cm.Greys) # array를 matrix로 바꿔 이미지로서 보여줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas에서 했던 것을 numpy에서 시행 해본 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target[0] # 0번째 데이터에 대한 target값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Matplotlib의 구성__  \n",
    "matplotlib로 그래프를 그릴 때 Figure 객체와 하나 이상의 subplot(Axes) 객체가 필요하다.  \n",
    "그리고 다시 Axes 객체는 2개의 Axis객체를 포함한다.  \n",
    "여기서 Axis 객체가 x축, y축을 나타낸다.  \n",
    "  \n",
    "[matplotlib 구성에 대한 포스트 링크](https://wikidocs.net/4763)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEYCAYAAAB1MrwpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nagBIHI0aABJHowaAxNGoASBx/x893mPL2iSc/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fb843dd240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4,4) # grid를 4x4로 나뉨\n",
    "# subplot(=Axes)들과 subplot들을 감싸줄 figure을 만들어낸다.\n",
    "\n",
    "for x,y, ax in zip(digits.data, digits.target, axes.ravel()):  #ravel() -> flatten\n",
    "# digits 데이터셋의 데이터, 타겟, 그리고 행렬로 되어진 subplot에 대한 반복문\n",
    "    ax.set_title(y) # subplot에 title을 붙여준다. \n",
    "    ax.imshow(x.reshape(8,8), cmap=\"Greys\") # 8X8 이미지를 'Greys'색으로 보여준다.\n",
    "    ax.set_xticks(()) # x 눈금 설정\n",
    "    ax.set_yticks(()) # y 눈금 설정\n",
    "plt.tight_layout() \n",
    "# subplot들간의 공간을 적용하기 위해 subplot 파라미터들의 dict타입 객체를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'b'), (3, 'c')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = ['a','b','c']\n",
    "c = zip(a,b)\n",
    "list(c) \n",
    "# zip의 경우 이렇게 묶어주는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
    "# 우선 training set, test set을 분리한다.\n",
    "# Default가 66%이기 때문에 train : test = 2 : 1 비율로 분리해준다.\n",
    "# overfitting 방지위해서 training, test set을 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1347, 64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train) # training(=fitting) 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   1.,   9.,  16.,  16.,  15.,   3.,   0.,   0.,   8.,  16.,\n",
       "        12.,   8.,   8.,   3.,   0.,   0.,   6.,  16.,   9.,   3.,   0.,\n",
       "         0.,   0.,   0.,   8.,  16.,  16.,  16.,   4.,   0.,   0.,   0.,\n",
       "         3.,   6.,   4.,  13.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         8.,  13.,   0.,   0.,   0.,   0.,   5.,   8.,  15.,  10.,   0.,\n",
       "         0.,   0.,   0.,  11.,  16.,  11.,   1.,   0.,   0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0] #  테스트 셋의 데이터 첫번째 row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([X_test[0]]) # 해당 데이터에 대한 예측값 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99111111111111116"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test) \n",
    "# test set에 대해서 data에 대한 예측값과 target값을 비교하여 accuracy 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "# suppress=True 플래그 설정을 통해서 부동소수점 실수를 고정소수점 실수로 출력\n",
    "\n",
    "digits = load_digits() # 숫자 데이터를 불러온다.\n",
    "X, y = digits.data, digits.target # 각각 숫자 데이터, 그에대한 타겟값을 할당\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y) # train set, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "# unit variance(단위 분산)에 맞게 scale(범위)를 맞춰주고 평균을 제거해서\n",
    "# feature들을 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # 숫자를 어떠한 방식으로 변환시켜줄 것인가 도와줌\n",
    "# 똑같이 scikit에서 import해서 객체화한 다음 fit_transform()시켜서 쓰면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__표준화는 평균을 0, 표준편차를 1으로 만드는 것이다.__  \n",
    "이렇게 되면 데이터의 영향력이 줄어들도록 하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train) # training set에 대하여 평균과 표준편차를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "# 범위를 맞추고, 중점을 잡아서 표준화를 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.33235445, -0.44833607, ..., -1.13622626,\n",
       "        -0.50355172, -0.19314451],\n",
       "       [ 0.        , -0.33235445, -0.65831822, ...,  1.57082087,\n",
       "         1.95133127, -0.19314451],\n",
       "       [ 0.        , -0.33235445,  1.02153903, ..., -0.62865492,\n",
       "        -0.50355172, -0.19314451],\n",
       "       ..., \n",
       "       [ 0.        ,  1.9575762 ,  1.23152118, ...,  1.06324954,\n",
       "         3.42426106,  0.35572818],\n",
       "       [ 0.        , -0.33235445, -1.07828253, ...,  1.40163043,\n",
       "        -0.01257512, -0.19314451],\n",
       "       [ 0.        , -0.33235445, -0.44833607, ..., -1.13622626,\n",
       "        -0.50355172, -0.19314451]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(X_train) # 위의 fit과 transform을 한꺼번에 해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit, transform의 경우 일관된 형식으로 쓸 수 있고, fit_transform의 경우 한번에 fit과 transform을 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0992207737387962e-18"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(X_train).mean() # 표준화 이후 거의 평균이 0이 나옴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기\n",
    " - pandas\n",
    "  - info\n",
    "  - describe\n",
    "  - head, tail, sample\n",
    "  - groupby, plot\n",
    " - numpy\n",
    "  - matplotlib\n",
    " - ML(Machine Learning) 용 데이터 변환 -> 데이터를 Numeric하게 바꿔야함.\n",
    "  - label encoding -> ordinal data\n",
    "  - One-hot encoding -> categorical data.  다만 category가 많을 경우 벡터의 차원수가 늘어나면서 performance 저하\n",
    " - 데이터 변환 ( 성능 향상 위해 Normalization )\n",
    "  - scaler 사용\n",
    "\n",
    "데이터 전처리\n",
    " - Missing\n",
    " - Duplicated\n",
    "\n",
    "데이터 수에 따라\n",
    "- 데이터가 많을 때 (경험에 의해서 판별)\n",
    " - train_test_split ( overfitting을 막기위해서 )\n",
    " - 알고리즘 적용\n",
    "  - from sklearn.알고리즘분류 import XClassfier (분류기의 경우 이렇게 불러온다.)\n",
    "   - instantiate\n",
    "   - fit\n",
    "   - score , pca\n",
    "   ( pca : 데이터의 분산(variance)를 최대한 보존하면서 서로 직교하는 새 축을 찾아서, 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간으로 변환하는 기법)\n",
    "   - 이렇게 해서 score가 높지 않을 경우 전처리부분으로 돌아간다.\n",
    " \n",
    "- 데이터가 적을 때\n",
    " - cross-validation -> 보통 10 folds로 쓴다.\n",
    "  - 기본적인 cross-validation\n",
    "  - stratified -> dummy Classifier에도 나왔던 용어. 클래스(라벨) 개수를 고려해서 나눠주는 것이다. 클래스의 분포를 비슷하게 샘플링 해준다.\n",
    "  - shuffle -> 데이터 양이 너무 적어서 sampling할 때 중복을 허용한다.\n",
    "  - group -> 항상 grouping 되어야 하는 데이터일 경우에 사용.\n",
    " - cross-validation은 최종 모델이 아니다!!!!! -> 데이터 모델로 성능 예측용\n",
    " \n",
    "- GridSearchCV -> hyper parameter를 찾는데 사용 (데이터 적을 때나 많을 때나 사용)\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris() #iris 데이터 로딩\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)\n",
    "# training set, test set을 나눠줌.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier() # KNN 분류기\n",
    "knn.fit(X_train, y_train) # 분류기 fitting\n",
    "knn.score(X_test, y_test) # 분류기의 average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "# 표준 스케일. 평균과 표준편차를 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standard = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_scaler = standard.fit_transform(X_train) # training set 표준화 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_scaler = standard.fit_transform(X_test) # test set 표준화 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn2 = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2.fit(X_train_scaler, y_train) # 표준화해준 데이터에 대해서 모델 fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2.score(X_test_scaler, y_test) # 표준화해준 test set으로 average 구해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=5) # 5 Nearest Neighbor 분류기\n",
    "knn3.fit(X_train, y_train) # fitting\n",
    "knn3.score(X_test, y_test) # average 구해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97368421052631582"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 최대/최소값이 각각 1,0이 되도록 scaling해준다.\n",
    "minMax = MinMaxScaler()\n",
    "X_train_scaler = minMax.fit_transform(X_train)\n",
    "X_test_scaler = minMax.fit_transform(X_test)\n",
    "knn4 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn4.fit(X_train_scaler, y_train)\n",
    "knn4.score(X_test_scaler, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn5.fit(X_train, y_train)\n",
    "knn5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "# 중앙값(median)과 IQR(Interquartile range) 사용. Outlier의 영향을 최소화 해준다.\n",
    "\n",
    "rb = RobustScaler()\n",
    "X_train_scaler = rb.fit_transform(X_train)\n",
    "X_test_scaler = rb.fit_transform(X_test)\n",
    "knn6 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn6.fit(X_train_scaler, y_train)\n",
    "knn6.score(X_test_scaler, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### principal component analysis -> unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pca : 데이터의 분산(variance)를 최대한 보존하면서 서로 직교하는 새 축을 찾아서, 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간으로 변환하는 기법  \n",
    "\n",
    "[PCA(Principal Component Analysis) 관련 설명 포스트 링크](https://ratsgo.github.io/machine%20learning/2017/04/24/PCA/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) # instantiate \n",
    "# column이 2로 바뀌는 것임. 각각이 4차원으로 특징을 갖고 있던것이 2차원으로 축소됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X) # fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-177.43997645500735"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.score(X, y) # 모든 샘플들에 대한 평균 로그 우도(likelihood) 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "likelihood(우도) : 어떤 시행의 결과 (Evidence) E 가 주어졌다 할 때, 만일 주어진 가설 H 가 참이라면, 그러한 결과 E 가 나올 정도는 얼마나 되겠느냐 하는 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1797, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "X_pca = pca.transform(X) # 표준화\n",
    "X_pca.shape # 표준화 이후 shape가 달라짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.9801047884967931"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_pca) #표준화 이후 모델 fitting\n",
    "pca.score(X_pca, y) # 모든 샘플들에 대한 평균 로그 우도(likelihood) 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampling문제 때문에 할 때 마다 학습 데이터가 변해서 결과값이 계속 변할 것.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data가 엄청나게 많은 경우에 sampling하면 그 데이터가 대표할 수 있다는 전제하에서 하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise는 추천 시스템을 분석하고 빌딩하는 Python sciki(short for SciPy Toolkits)이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlgoBase',\n",
       " 'BaselineOnly',\n",
       " 'CoClustering',\n",
       " 'Dataset',\n",
       " 'GridSearch',\n",
       " 'KNNBaseline',\n",
       " 'KNNBasic',\n",
       " 'KNNWithMeans',\n",
       " 'KNNWithZScore',\n",
       " 'NMF',\n",
       " 'NormalPredictor',\n",
       " 'Prediction',\n",
       " 'PredictionImpossible',\n",
       " 'Reader',\n",
       " 'SVD',\n",
       " 'SVDpp',\n",
       " 'SlopeOne',\n",
       " 'Trainset',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'accuracy',\n",
       " 'builtin_datasets',\n",
       " 'dataset',\n",
       " 'dump',\n",
       " 'evaluate',\n",
       " 'get_dataset_dir',\n",
       " 'get_distribution',\n",
       " 'model_selection',\n",
       " 'prediction_algorithms',\n",
       " 'print_perf',\n",
       " 'reader',\n",
       " 'similarities',\n",
       " 'trainset',\n",
       " 'utils']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(surprise) # 지원하는 양이 pandas의 30분의 1도 안될 정도로 적다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'construct_testset',\n",
       " 'construct_trainset',\n",
       " 'folds',\n",
       " 'load_builtin',\n",
       " 'load_from_df',\n",
       " 'load_from_file',\n",
       " 'load_from_folds',\n",
       " 'read_ratings']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(surprise.Dataset) # 클래스의 메소드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "surprise.Dataset.load_from_df 를 이용해서 pandas로 불러온 데이터를 불러올 수 있다.  \n",
    "load_builtin 으로 데이터를 바로 쓸 수 있게 해줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = surprise.Dataset.load_builtin('ml-100k')\n",
    "# surprise에 내장되어있는 데이터셋 불러옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x1fb8521f710>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('196', '242', 3.0, '881250949'),\n",
       " ('186', '302', 3.0, '891717742'),\n",
       " ('22', '377', 1.0, '878887116'),\n",
       " ('244', '51', 2.0, '880606923'),\n",
       " ('166', '346', 1.0, '886397596'),\n",
       " ('298', '474', 4.0, '884182806'),\n",
       " ('115', '265', 2.0, '881171488'),\n",
       " ('253', '465', 5.0, '891628467'),\n",
       " ('305', '451', 3.0, '886324817'),\n",
       " ('6', '86', 3.0, '883603013')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.raw_ratings[:10]\n",
    "# 데이터 일부 불러옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame.from_records(data.raw_ratings)\n",
    "# pandas에서 record들을 DataFrame객체로 불러 올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1.rename({ 0:'user',1:'item',2:'rate',3:'time'},axis=1,inplace=True)\n",
    "# axis =1 -> Column명을 다시 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data1.drop('time',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user item  rate       time\n",
       "0  196  242   3.0  881250949\n",
       "1  186  302   3.0  891717742\n",
       "2   22  377   1.0  878887116\n",
       "3  244   51   2.0  880606923\n",
       "4  166  346   1.0  886397596"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      "user    100000 non-null object\n",
      "item    100000 non-null object\n",
      "rate    100000 non-null float64\n",
      "time    100000 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from surprise import Reader\n",
    "# Reader 클래스는 평가(rating)를 포함하는 파일을 parsing하는데 쓰인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-3f2305f951bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msurprise_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurprise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\surprise\\dataset.py\u001b[0m in \u001b[0;36mload_from_df\u001b[1;34m(cls, df, reader)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDatasetAutoFolds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_ratings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\surprise\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ratings_file, reader, df)\u001b[0m\n\u001b[0;32m    288\u001b[0m             self.raw_ratings = [(uid, iid, float(r) + self.reader.offset, None)\n\u001b[0;32m    289\u001b[0m                                 \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                                 self.df.itertuples(index=False)]\n\u001b[0m\u001b[0;32m    291\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Must specify ratings file or dataframe.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\surprise\\dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             self.raw_ratings = [(uid, iid, float(r) + self.reader.offset, None)\n\u001b[0m\u001b[0;32m    289\u001b[0m                                 \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                                 self.df.itertuples(index=False)]\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "surprise_data = surprise.Dataset.load_from_df(data1, reader)\n",
    "# 계속 에러가 뜬다 그 이유는?\n",
    "\n",
    "# df(`Dataframe`): The dataframe containing the ratings. It must have\n",
    "#         three columns, corresponding to the user (raw) ids, the item\n",
    "#         (raw) ids, and the ratings, in this order.\n",
    "\n",
    "# DataFrame이 user id, item id, rating 순으로 3가지의 Columns을 지니는 형태로 넣어야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "surprise_data = surprise.Dataset.load_from_df(data1.iloc[:,:-1], reader)\n",
    "# 그래서 data1의 뒷쪽 column \"Time\"을 빼고 넣었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# cross_validate : Cross-validation으로 알고리즘을 진행하며, \n",
    "# accuracy 척도와 계산 시간을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from surprise import NormalPredictor\n",
    "# training set의 분산에 기반하여 random 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algo = NormalPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': (0.13962650299072266, 0.09910321235656738),\n",
       " 'test_mae': array([ 1.22006477,  1.21983972]),\n",
       " 'test_rmse': array([ 1.51863964,  1.51930784]),\n",
       " 'test_time': (0.47580504417419434, 0.3087129592895508)}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(algo, surprise_data, cv=2)\n",
    "# surprise_dat로 algo(=NormalPredictor)를 평가한다.\n",
    "# cv = 2 -> 2개로 나뉜다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame.from_records(data.raw_ratings, columns = ['user', 'item', 'rate', 'time'])\n",
    "# surprise로 불러온 data를 pandas로 DataFrame객체로 만들어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x.drop('time',axis=1,inplace=True)\n",
    "# axis=1 -> Column 상에서 'time'이라는 Column을 날려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user item  rate\n",
       "0  196  242   3.0\n",
       "1  186  302   3.0\n",
       "2   22  377   1.0\n",
       "3  244   51   2.0\n",
       "4  166  346   1.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      user\n",
       "item  196      242\n",
       "      186      302\n",
       "      22       377\n",
       "      244       51\n",
       "      166      346\n",
       "      298      474\n",
       "      115      265\n",
       "      253      465\n",
       "      305      451\n",
       "      6         86\n",
       "      62       257\n",
       "      286     1014\n",
       "      200      222\n",
       "      210       40\n",
       "      224       29\n",
       "      303      785\n",
       "      122      387\n",
       "      194      274\n",
       "      291     1042\n",
       "      234     1184\n",
       "      119      392\n",
       "      167      486\n",
       "      299      144\n",
       "      291      118\n",
       "      308        1\n",
       "      95       546\n",
       "      38        95\n",
       "      102      768\n",
       "      63       277\n",
       "      160      234\n",
       "              ... \n",
       "rate  449        1\n",
       "      661        2\n",
       "      721        3\n",
       "      821        4\n",
       "      764        3\n",
       "      537        3\n",
       "      618        2\n",
       "      487        3\n",
       "      113        5\n",
       "      943        2\n",
       "      864        4\n",
       "      750        3\n",
       "      279        1\n",
       "      646        3\n",
       "      654        2\n",
       "      617        4\n",
       "      913        3\n",
       "      660        2\n",
       "      421        4\n",
       "      495        4\n",
       "      806        4\n",
       "      676        4\n",
       "      721        3\n",
       "      913        2\n",
       "      378        3\n",
       "      880        3\n",
       "      716        5\n",
       "      276        1\n",
       "      13         2\n",
       "      12         3\n",
       "Length: 200000, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.set_index(['user']).unstack()\n",
    "# 'user' Column을 index로 설정해주고 unstack해준다.\n",
    "# user-item, user-rate로 구성된 Series객체 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 943 entries, 1 to 99\n",
      "Columns: 1682 entries, 1 to 999\n",
      "dtypes: float64(1682)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": [
    "y = x.pivot('user','item','rate') \n",
    "# 'user'를 인덱스로 삼으며,  item 항목들을 Columns으로 만들어 버리며,\n",
    "# 이러한 row, column에 대한 value값에 rate값이 나온다.\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item    1   10  100  1000  1001  1002  1003  1004  1005  1006 ...   990  991  \\\n",
       "user                                                          ...              \n",
       "1     5.0  3.0  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "10    4.0  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "100   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   3.0  NaN   \n",
       "101   3.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "102   3.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "103   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "104   NaN  2.0  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "105   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "106   4.0  NaN  3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "107   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "108   4.0  5.0  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "109   4.0  NaN  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "11    NaN  NaN  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "110   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "111   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "112   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "113   NaN  NaN  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "114   NaN  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "115   NaN  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "116   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "117   4.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "118   NaN  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "119   NaN  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "12    NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "120   4.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "121   4.0  NaN  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "122   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "123   NaN  NaN  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "124   3.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "125   4.0  NaN  NaN   3.0   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "...   ...  ...  ...   ...   ...   ...   ...   ...   ...   ... ...   ...  ...   \n",
       "921   3.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "922   5.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "923   3.0  NaN  5.0   NaN   1.0   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "924   5.0  NaN  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "925   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "926   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "927   5.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "928   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "929   3.0  NaN  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "93    5.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "930   3.0  NaN  3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "931   NaN  NaN  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "932   4.0  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "933   3.0  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "934   2.0  NaN  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "935   3.0  NaN  3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "936   4.0  NaN  4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "937   NaN  NaN  3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "938   4.0  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "939   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "94    4.0  NaN  5.0   NaN   NaN   NaN   NaN   3.0   NaN   NaN ...   NaN  NaN   \n",
       "940   NaN  NaN  3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "941   5.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "942   NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "943   NaN  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "95    5.0  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "96    5.0  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "97    4.0  NaN  2.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "98    NaN  NaN  NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "99    4.0  NaN  5.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN ...   NaN  NaN   \n",
       "\n",
       "item  992  993  994  995  996  997  998  999  \n",
       "user                                          \n",
       "1     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "10    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "100   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "101   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "102   NaN  2.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "103   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "104   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "105   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "106   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "107   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "108   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "109   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "11    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "110   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "111   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "112   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "113   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "114   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "115   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "116   NaN  2.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "117   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "118   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "119   NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN  \n",
       "12    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "120   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "121   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "122   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "123   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "124   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "125   NaN  NaN  NaN  NaN  3.0  2.0  NaN  4.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "921   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "922   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "923   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "924   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "925   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "926   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "927   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "928   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "929   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "93    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "930   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "931   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "932   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "933   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "934   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "935   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "936   NaN  NaN  NaN  3.0  NaN  NaN  NaN  NaN  \n",
       "937   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "938   NaN  5.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "939   NaN  4.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "94    NaN  4.0  NaN  NaN  NaN  4.0  NaN  NaN  \n",
       "940   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "941   NaN  4.0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "942   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "943   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "95    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "96    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "97    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "98    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "99    NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[943 rows x 1682 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADfCAYAAAD4Bhh5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fb849c69e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y)\n",
    "plt.grid(True)\n",
    "\n",
    "# 기본적으로 sparse하다.\n",
    "\n",
    "# x축은 item, y축은 user이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly # 가장 기본적인 알고리즘 적용.\n",
    "# Algorithm predicting the baseline estimate for given user and item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = surprise_data.build_full_trainset()\n",
    "#데이터셋을 나누지 말고 모든 데이터를 trainset으로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x1fb84dd62b0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo1 = surprise.BaselineOnly()\n",
    "algo1.fit(train_data) # fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algo1은 이제 training 된 상황이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='1', iid='1', r_ui=None, est=3.8923532488948851, details={'was_impossible': False})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo1.predict('1','1') #user, item 값을 각각 1을 줘서 predict했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algo = surprise.KNNBasic() # 기본적인 collaborative filtering 알고리즘 객체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "surprise포맷으로 불러 들인다.<br>\n",
    "user,item, rating이 필요하다.<br>\n",
    "fit시키기 위해서 build_full_trainset()으로 training set을 만들어준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1fb84e30898>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='1', iid='1', r_ui=None, est=4.1299713089494405, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.predict('1','1') # user, item에 각각 1값을 줘서 predict해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SVD(Singular Value Decomposition)__   \n",
    "  \n",
    "특이값분해는 m x n 크기의 데이터 행렬 A를 아래와 같이 분해하는 걸 말합니다.\n",
    "\n",
    "$$A=UΣVT$$\n",
    "<img src=\"http://i.imgur.com/lP44bGq.png\"/>\n",
    "\n",
    "[SVD 관련 포스트 링크1](http://rfriend.tistory.com/185)  \n",
    "[SVD 관련 포스트 링크2](https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/04/06/pcasvdlsa/)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': (6.13857364654541,\n",
       "  6.398183584213257,\n",
       "  9.362856388092041,\n",
       "  8.55200743675232,\n",
       "  9.652127265930176),\n",
       " 'test_mae': array([ 0.7451691 ,  0.74455542,  0.73519866,  0.73194463,  0.73952187]),\n",
       " 'test_rmse': array([ 0.94400927,  0.94427613,  0.93198751,  0.92895999,  0.93597631]),\n",
       " 'test_time': (0.16951537132263184,\n",
       "  0.16060328483581543,\n",
       "  0.29125428199768066,\n",
       "  0.16951656341552734,\n",
       "  0.5824418067932129)}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k') # built-in dataset을 불러온다.\n",
    "algo = SVD() # SVD 알고리즘\n",
    "\n",
    "cross_validate(algo, data, cv=5)\n",
    "# 5등분한 data에 대해 cross validation을 이용해서 실행 시간, 정확도를 출력해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV는 cross-validation을 이용해서 parameter를 찾는것이다.\n",
    "parameter에 따라서 performance가 좌지우지 되기 때문에 찾는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 성능이 좋은 파라미터를 찾는다.<br>\n",
    "grid 방식. randomize 방식."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid방식의 경우 training할 때 굉장히 많은시간 소요. <br>\n",
    "\n",
    "randomize방식의 경우 확률적인 것에 기인해서 training. 그래서 시간이 좀 덜 걸린다. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn은 메모리 베이스"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
